import tushare as ts
import json
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

import seaborn as sns
import numpy as np
from scipy.stats import norm
from tqdm import tqdm

import akshare as ak

class PortfolioStressTester:
    def __init__(self, config_path="config.json", portfolio_path=None):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)

        # åŸºç¡€é…ç½®
        self.token = self.config["TUSHARE_TOKEN"]
        ts.set_token(self.token)
        self.pro = ts.pro_api()


        self.lookback_years = self.config["DEFAULT_LOOKBACK_YEARS"]
        self.days = self.config["DEFAULT_VAR_DAYS"]
        self.stress_level = self.config["DEFAULT_STRESS_LEVEL"]


        self.us_sub = self.config["US_INDEX"] # ä¹Ÿå°±æ˜¯SPY
        self.hk_sub = self.config["HK_INDEX"] # ä¹Ÿå°±æ˜¯HSI
        self.cn_sub = self.config["CN_INDEX"] # ä¹Ÿå°±æ˜¯csi500
        self.hk_industry_index_map = self.config["HK_SECTOR_TO_INDEX"] 

        
        # è¯»å–æŒä»“è¡¨
        self.portfolio_df = None
        if portfolio_path:
            df1= pd.read_excel(portfolio_path)
            #print(df1["è¡Œä¸šä¿¡æ¯"].unique())
            self.portfolio_df =  df1
            #print(self.portfolio_df["è¡Œä¸šä¿¡æ¯"].unique())
            date_col = "äº¤æ˜“æ—¥" if "äº¤æ˜“æ—¥" in df1.columns else "date"
            #self.portfolio_df = df
            self.last_trade_date = datetime.strptime(str(df1[date_col].max()),"%Y%m%d") #æœ€åäº¤æ˜“æ—¥
            self.start_date = (self.last_trade_date - timedelta(days=365 * self.lookback_years))

            if self.hk_sub == "industry":
                self.hk_industry_df = self.init_hk_ind()

            #self.start_date = (self.last_trade_date - timedelta(days=365 * self.lookback_years))
            print(self.last_trade_date)
            self.initialize_market_and_sector_returns()


    def init_hk_ind(self):
        all_dfs = []
        print("è·å–hkè¡Œä¸šèµ°åŠ¿ä¸­")
        for sector, sym in tqdm(self.hk_industry_index_map.items()):
            #print("è·å–%sè¡Œä¸šæ•°æ®"%sector)
            try:
                df = ak.stock_hk_index_daily_em(symbol=sym)
                if df is None or df.empty:
                    print(f"[è­¦å‘Š] {sector} ({sym}) æ— æ•°æ®")
                    continue
                # ç»Ÿä¸€åˆ—åæˆ–ä¿ç•™åŸæ ·
                df = df.copy()
                df["sector"] = sector
                df["symbol"] = sym
                df["return"] = df["latest"].pct_change()
                all_dfs.append(df)
                print(df['date'].min())
            except Exception as e:
                print(f"[é”™è¯¯] æ‹‰å– {sector} ({sym}) å¤±è´¥: {e}")

        if all_dfs:
            big_df = pd.concat(all_dfs, ignore_index=True)
            big_df['trade_date'] = big_df['date'].astype(str).str.replace("-","")
            big_df = big_df[big_df['trade_date']>=(self.start_date.strftime("%Y%m%d"))]
            big_df = big_df[big_df['trade_date']<=(self.last_trade_date.strftime("%Y%m%d"))]
            big_df = big_df.set_index("trade_date")[["return","sector"]]
            
            print(big_df)
        else:
            big_df = pd.DataFrame()

        return big_df
            


    def initialize_market_and_sector_returns(self):
        """
        åœ¨ __init__ ä¸­è°ƒç”¨ï¼š
        - è·å– US_INDEXã€HK_INDEXã€CN_INDEX çš„æ—¥æ”¶ç›Šç‡
        - ä½†æ˜¯å¦‚æœself.hk_sub == â€œindustryâ€ï¼Œé‚£ä¹ˆself.hk_returnå°±æ˜¯inité˜¶æ®µæ‰€æœ‰ æ¸¯è‚¡æŒä»“çš„è¡Œä¸šï¼ˆl2_codeï¼‰å¯¹åº”çš„æŒ‡æ•°æ”¶ç›Šç‡
        å­˜å‚¨åˆ°ï¼š
            - self.us_return
            - self.hk_return
            - self.cn_return
        """
        if self.portfolio_df is None or self.last_trade_date is None:
            return

        # å‚æ•°
        last_date_str = self.last_trade_date.strftime("%Y%m%d")
        start_date_str = self.start_date.strftime("%Y%m%d")

        # è·å– config ä¸­çš„æ›¿ä»£æŒ‡æ•°
        self.us_index_code = self.us_sub
        self.hk_index_code = self.hk_sub
        self.cn_index_code = self.cn_sub

        def get_index_return(ts_code):
            try:
                df = self.pro.index_global(ts_code=ts_code, start_date=start_date_str, end_date=last_date_str)
                df = df.sort_values("trade_date")
                df["return"] = df["close"].pct_change()
                print(df)
                return df.set_index("trade_date")["return"]
            except Exception as e:
                print(f"âŒ è·å–æŒ‡æ•° {ts_code} å¤±è´¥: {e}")
                return pd.Series()
            
        # ç¾è‚¡ä¸æ¸¯è‚¡åŸºå‡†æ”¶ç›Š
        self.us_return = get_index_return(self.us_index_code)

        if self.hk_index_code != "industry":
            self.hk_return = get_index_return(self.hk_index_code)
        else:
            print("using industry performance for hk missing returns")
            self.hk_hsi = get_index_return("HSI") #save for replacement
            self.hk_return = self.hk_industry_df


        cn_df = self.pro.index_daily(ts_code=self.cn_index_code, start_date=start_date_str, end_date=last_date_str)
        #print(cn_df)
        cn_df  = cn_df .sort_values("trade_date")
        cn_df["return"] = cn_df["close"].pct_change()
        print(cn_df)
        self.cn_return = cn_df.set_index("trade_date")["return"]
        

        self.init_md()
        #print(self.us_return)
        #print(self.hk_return)



    def eda_print(self, plot=False):
        if self.portfolio_df is None:
            raise ValueError("æœªåŠ è½½æŒä»“æ•°æ®ã€‚")

        df = self.portfolio_df.copy()
        df = df.rename(columns={
            "äº¤æ˜“æ—¥": "date",
            "æ ‡çš„ä»£ç ": "ticker",
            "æ ‡çš„åç§°": "name",
            "åä¹‰æœ¬é‡‘": "notional",
            "è¡Œä¸šä¿¡æ¯": "sector"
        })
        df["date"] = pd.to_datetime(df["date"], format="%Y%m%d")
        
        print("\n åŸºç¡€ä¿¡æ¯")
        print(f"- æŒä»“è®°å½•æ€»æ•°: {len(df)}")
        print(f"- æ—¥æœŸèŒƒå›´: {df['date'].min().date()} ~ {df['date'].max().date()}")
        print(f"- ä¸åŒæŒä»“æ—¥æœŸæ•°: {df['date'].nunique()}")

        print("\n -- æ¯æ—¥æŒä»“èµ„äº§æ•°é‡ï¼ˆå‰10è¡Œï¼‰")
        print(df.groupby("date")["ticker"].nunique().head(10))

        print("\n -- æ¯æ—¥åä¹‰æœ¬é‡‘æ€»é¢ï¼ˆå•ä½ï¼šå…ƒï¼‰")
        print(df.groupby("date")["notional"].sum().describe())

        print("\n -- ç¼ºå¤±å€¼æ£€æŸ¥")
        print(df[["ticker", "name", "sector", "notional"]].isna().sum())

        print("\n -- è¡Œä¸šé›†ä¸­åº¦ï¼ˆæŒ‰åä¹‰æœ¬é‡‘åŠ æ€»ï¼‰")
        print(df.groupby("sector")["notional"].sum().sort_values(ascending=False).head(10))

        print("\n -- ä¸ªè‚¡æŒä»“å‰10ï¼ˆæŒ‰åä¹‰æœ¬é‡‘åŠ æ€»ï¼‰")
        print(df.groupby(["ticker", "name"])["notional"].sum().sort_values(ascending=False).head(10))

        if plot:
            try:
                import matplotlib.pyplot as plt
                df_count = df.groupby("date")["ticker"].nunique()
                plt.figure(figsize=(10, 3))
                df_count.plot(title="æ¯æ—¥æŒä»“èµ„äº§æ•°é‡")
                plt.xlabel("æ—¥æœŸ")
                plt.ylabel("èµ„äº§æ•°")
                plt.tight_layout()
                plt.show()
            except:
                print("---- ç»˜å›¾å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç¯å¢ƒä¸æ”¯æŒã€‚")

    def identify_market(self,ticker: str) -> str:
        """
        æ ¹æ®æ ‡çš„ä»£ç åç¼€è¯†åˆ«å¸‚åœºï¼šAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ã€‚é»˜è®¤ä½¿ç”¨ config fallbackã€‚
        """
        ticker = ticker.upper()
        if ticker.endswith(".SH") or ticker.endswith(".SZ"):
            return "CN"
        elif ticker.endswith(".SZHK") or ticker.endswith(".HK"):
            return "HK"
        elif ticker.endswith(".US"):
            return "US"
        else:
            return "UNKNOWN"
        

    from datetime import datetime, timedelta

    def fetch_price_series(self, tickers: list[str]):
        """
        è·å– Aè‚¡ï¼ˆTushareï¼‰+ æ¸¯è‚¡/ç¾è‚¡ï¼ˆAkShareï¼‰å†å²å‰å¤æƒæ”¶ç›˜ä»·ï¼Œå¹¶ä¿å­˜ä¸º CSV
        è¿”å›ï¼š{ticker: pd.Series of close prices}
        """
        import tushare as ts
        import akshare as ak
        import pandas as pd
        import os
        from datetime import datetime, timedelta

        start_date = self.start_date.strftime("%Y%m%d")
        end_date = self.last_trade_date.strftime("%Y%m%d")
        today_str = datetime.today().strftime("%Y%m%d")

        price_data = {}
        printed = 0
        for ticker in tqdm(tickers):
            market = self.identify_market(ticker)
            print(ticker,market)


            try:
                if market == "CN":
                    
                    df = self.pro.daily(ts_code = ticker,start_date=start_date, end_date = end_date)
                    #print(df)
                    if df is not None and not df.empty:
                        print('good')
                        df = df.sort_values("trade_date")
                        series = df.set_index("trade_date")["close"]
                        price_data[ticker] = series.astype(float)
                    else:
                        print("empty ", ticker)

                elif market == "HK":
                    code = ticker.replace(".SZHK", "").replace(".HK", "")#.zfill(4)
                    print(code)
                    df = ak.stock_hk_hist(symbol=code, start_date=start_date, end_date=end_date)
                    if not df.empty:
                        print('good')
                        df = df.rename(columns={"æ—¥æœŸ": "date", "æ”¶ç›˜": "close"})
                        df["date"] = pd.to_datetime(df["date"])
                        df["date"] = df["date"].dt.strftime("%Y%m%d")
                        price_data[ticker] = df.set_index("date")["close"].astype(float)
                    else:
                        print("empty ", ticker)

                elif market == "US":
                    symbol = ticker.replace(".US", "")
                    print(symbol)
                    df = ak.stock_us_daily(symbol=symbol, adjust="qfq")
                    if not df.empty:
                        print('good')
                        df = df.rename(columns={"æ—¥æœŸ": "date", "æ”¶ç›˜": "close"})
                        df["date"] = pd.to_datetime(df["date"])
                        df["date"] = df["date"].dt.strftime("%Y%m%d")
                        df = df[(df["date"] >= start_date) & (df["date"] <= end_date)]
                        price_data[ticker] = df.set_index("date")["close"].astype(float)
                    else:
                        print("empty ", ticker)

                else:
                    print(f"âš ï¸ ä¸æ”¯æŒçš„å¸‚åœºæˆ–æ ¼å¼ï¼š{ticker}")
                printed = printed+1
                print(printed)

            except Exception as e:
                print(f"è·å– {ticker} æ•°æ®å¤±è´¥ï¼š{e}")

        # åˆå¹¶ä¸º DataFrame å¹¶ä¿å­˜
        if price_data:
            print(len(price_data))
            df_merged = pd.concat(price_data, axis=1).sort_index()
            print(df_merged.shape[1])
            df_merged["date"] = df_merged.index.astype(str)
            df_merged = df_merged.reset_index(drop=True)
            os.makedirs("data", exist_ok=True)
            save_path = f"data/prices_{self.last_trade_date.strftime("%Y%m%d")}.csv"
            #df_merged.to_csv(save_path)
            #print(f"ä»·æ ¼æ•°æ®å·²ä¿å­˜è‡³ {save_path}")
        else:
            #print("âš ï¸ æ— ä»·æ ¼æ•°æ®å¯ä¿å­˜")
            pass

        return price_data,df_merged

    def init_md(self):
        if self.portfolio_df is None:
            raise ValueError("æœªåŠ è½½æŒä»“æ•°æ®")

        df = self.portfolio_df.rename(columns={
            "äº¤æ˜“æ—¥": "date",
            "æ ‡çš„ä»£ç ": "ticker",
            #"åä¹‰æœ¬é‡‘": "notional",
            "æ ‡çš„æ•°é‡": "vol",
            "è¡Œä¸šä¿¡æ¯": "sector"
        }).copy()

        df["date"] = pd.to_datetime(df["date"], format="%Y%m%d")

        latest_date = df["date"].max()
        df_latest = df[df["date"] == latest_date].groupby('ticker').agg({
            #"notional": "sum",
            "vol":"sum",
            "sector": "first"   # æˆ–è€… lambda x: x.iloc[0]
        })


        ticker_to_sector = dict(zip(df_latest.index, df_latest["sector"]))
       # print(ticker_to_sector)


        df_latest["ticker"] = df_latest.index

        self.weights = df_latest.set_index("ticker")["vol"]
        self.total_size = self.weights.sum()
        self.weights = self.weights / self.weights.sum()
        tickers = self.weights.index.tolist()


        price_data,price_df = self.fetch_price_series(tickers)
        latest_price_data = price_df[price_df['date']==self.last_trade_date.strftime("%Y%m%d")].T
        latest_price_data.columns = ['price']
        df_latest = df_latest.merge(latest_price_data,how="left",right_index = True, left_index = True)
        df_latest['size'] = df_latest['vol']*df_latest['price']

        self.weights = df_latest.set_index("ticker")["size"]
        print(len(self.weights))
        self.total_size = self.weights.sum()
        print('total size is: %s' % self.total_size)
        self.weights = self.weights / self.weights.sum()
        tickers = self.weights.index.tolist()

        
        print(df_latest)
        print(f"\nğŸ“Œ æœ€æ–°æŒä»“æ—¥æœŸï¼š{latest_date.date()}ï¼Œå…± {len(tickers)} ä¸ªæ ‡çš„")
        

        # æ•´åˆä»·æ ¼åºåˆ—ï¼Œè®¡ç®—æ”¶ç›Š
        aligned = pd.concat(price_data, axis=1).sort_index()#.dropna()
        #aligned.to_excel("aligned.xlsx")
        returns = aligned.pct_change()
        #returns.to_excel("result.xlsx")
        # éå†æ¯åˆ—ï¼Œæ ¹æ® ticker åˆ¤æ–­å¸‚åœºåï¼Œç”¨ç›¸åº”æŒ‡æ•° return æ›¿æ¢ NaN
        for col in returns.columns:
            if col.endswith((".SH", ".SZ")):
                sub_ret = self.cn_return
            elif col.endswith((".SZHK", ".HK")):
                if self.hk_index_code != "industry":
                    sub_ret = self.hk_return
                else:
                    #TODO
                    now_indus = ticker_to_sector[col]
                    #print(f"replacing {col} with {self.hk_industry_index_map[now_indus]}")
                    sub_ret = self.hk_industry_df[self.hk_industry_df['sector'] == now_indus]["return"] #æ­¤ä¹ƒå¯¹åº”industryçš„return
                    #print(sub_ret)
                    #print("hk subret")
                    #print(sub_ret)
                    #sub_ret = sub_ret[sub_ret.index]
                    #ä½¿ç”¨colåˆ¤æ–­è¿™ä¸ªhkè‚¡ç¥¨æ•°æ®å“ªä¸ªè¡Œä¸šï¼Œå¹¶åœ¨self.hk_returnä¸­æˆªå–å¯¹åº”è¡Œä¸šçš„returns
                    #print("ä½¿ç”¨è¡Œä¸šæ•°æ®æ›¿ä»£hkä¸ªè‚¡ç¼ºå¤±å€¼")
            elif col.endswith(".US"):
                #print("us subret")
                #print(sub_ret)
                sub_ret = self.us_return
            else:
                continue
            returns[col] = returns[col].fillna(sub_ret).fillna(0)

        self.returns = returns.fillna(0) #è€ƒè™‘åˆ°ä¸‰ä¸ªå¸‚åœºå­˜åœ¨ä¸ä¸€æ ·çš„äº¤æ˜“æ—¥ï¼Œnanæ—¥ç¡®è®¤å·²ä¸ºåˆ«çš„å¸‚åœºäº¤æ˜“æ—¶å€™ï¼Œè¯¥å¸‚åœºçš„ä¼‘æ¯æ—¥å› æ­¤æ”¶ç›Šä¸º0
        #returns.to_excel(f"data/returns_{self.last_trade_date.strftime("%Y%m%d")}.xlsx")
        #print(f"returnsæ•°æ®æ•´åˆå®Œæ¯•ç°åœ¨ä¿å­˜è‡³ï¼šdata/returns_{self.last_trade_date.strftime("%Y%m%d")}.xlsx")

    def run_stress_test(self, level = None, days = None,method = "parametric"):
        """
        æ‰§è¡Œä¸€æ¬¡å‹åŠ›æµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š
        - è¯»å–æœ€è¿‘æ—¥æœŸçš„æŒä»“æ•°æ®
        - æ ¹æ®æ ‡çš„è¯†åˆ«å¸‚åœºï¼Œè°ƒç”¨ fetch_price_series è·å–å†å²ä»·æ ¼
        - è®¡ç®—ç»„åˆæ”¶ç›Šåºåˆ—ã€VaRã€æœ€å¤§å›æ’¤
        - è¾“å‡ºè¡Œä¸šé›†ä¸­åº¦å’Œä¸ªè‚¡é›†ä¸­åº¦
        è¿”å›ï¼šdict æ ¼å¼ç»“æœ
        """

        if level is not None:
            y = level
        else:
            y = self.stress_level

        if days is not None:
            n = days
        else:
            n = self.days

        self.portfolio_returns = self.returns @ self.weights

        def calculate_var_maxloss(returns_df = self.returns, weights =self.weights, y=0.99,n=5, method = method):
            print()
            portfolio_returns = returns_df @ weights
            print(f"\n[VaRè®¡ç®—] è®¡ç®—æ–¹æ³•={method}, ç½®ä¿¡åº¦={y}, æ—¶é•¿(æ—¥)={n}")
            print(len(portfolio_returns))
            if method == "empirical":
                #portfolio_returns = returns_df @ weights
                n_day_returns = portfolio_returns.rolling(window=n).sum().dropna()
                
                var_y = np.quantile(n_day_returns, (1-y))
                max_loss = n_day_returns.min()
                print(f"ç»éªŒæ³•: VaR(%)={var_y:.4%},VaR(cny)={(var_y*portfolio_value)}, MaxLoss%={max_loss:.4%}, MaxLoss(cny)={max_loss*portfolio_value}")
                return var_y, max_loss
            
            elif method == "parametric":
                #portfolio_returns = returns_df @ weights
                mu = portfolio_returns.mean()
                sigma = portfolio_returns.std()
                z = norm.ppf(1 - y)
                var_1d = z * sigma - mu
                var_nd = var_1d * np.sqrt(n)
                print(f"æ­£æ€æ³•: z={z:.3f}, mu={mu:.4%}, sigma={sigma:.4%}, VaR(%)={var_nd:.4%}, VaR(cny)={(var_nd*portfolio_value)}")
                return var_nd, np.nan  # max_loss ä¸é€‚ç”¨äºæ­£æ€å‡è®¾ï¼Œå¯è¿”å› nan æˆ–è­¦å‘Š
                return
        
        portfolio_value = self.total_size
        #portfolio_returns = returns @ weights.loc[returns.columns]
        var_perc,max_loss_perc = calculate_var_maxloss(y = y, n = n)
        

        var,max_loss = var_perc*portfolio_value,max_loss_perc*portfolio_value
        #print(var1,var3,var5,var1_perc,var3_perc,var5_perc,max_loss)
        return var_perc,var,max_loss_perc, max_loss
    

    def gen_report(self):
        self.days_range = self.config["VAR_DAYS"]
        self.levels_range = self.config["VAR_LEVELS"]
        self.methods_range = self.config["METHODS"]

        print("Generating report using: ")
        print(self.days_range,self.levels_range,self.methods_range)


        results = []
        # è¿­ä»£ä¸åŒç»„åˆ
        for method in self.methods_range:
            for level in self.levels_range:
                for days in self.days_range:
                    print(f"Running stress test: method={method}, level={level}, days={days}")
                    var_perc, var_amt, max_loss_perc, max_loss_amt = self.run_stress_test(
                        level=level,
                        days=days,
                        method=method
                    )
                    results.append({
                        "method": method,
                        "level": level,
                        "days": days,
                        "var_perc": var_perc,
                        "var_amt": var_amt,
                        "max_loss_perc": max_loss_perc,
                        "max_loss_amt": max_loss_amt
                    })


                # è½¬ä¸º DataFrame å¹¶è¾“å‡º Excel
        df_result = pd.DataFrame(results)
        df_result.to_excel("stress_test_results.xlsx", index=False)
        print("âœ… å·²ä¿å­˜è‡³ stress_test_results.xlsx")

        # åªç»˜åˆ¶ä¸€ç§ method çš„çƒ­åŠ›å›¾ï¼ˆå¦‚ "empirical"ï¼‰
        df_plot = df_result[df_result["method"] == "empirical"]

        # æ„é€ é€è§†è¡¨ï¼šindex=days, columns=level, values=VaR%
        pivot_table = df_plot.pivot(index="days", columns="level", values="var_perc")

        # ç»˜åˆ¶çƒ­åŠ›å›¾
        plt.figure(figsize=(8, 5))
        sns.heatmap(pivot_table, annot=True, fmt=".2%", cmap="YlOrRd_r", cbar_kws={"label": "VaR (%)"})
        plt.title("VaR percentage heat map (empirical)")
        plt.xlabel("level of trust")
        plt.ylabel("days of holding")
        plt.tight_layout()
        plt.savefig("1.png")

        # åªç»˜åˆ¶ä¸€ç§ method çš„çƒ­åŠ›å›¾ï¼ˆå¦‚ "empirical"ï¼‰
        df_plot = df_result[df_result["method"] == "parametric"]

        # æ„é€ é€è§†è¡¨ï¼šindex=days, columns=level, values=VaR%
        pivot_table = df_plot.pivot(index="days", columns="level", values="var_perc")

        # ç»˜åˆ¶çƒ­åŠ›å›¾
        plt.figure(figsize=(8, 5))
        sns.heatmap(pivot_table, annot=True, fmt=".2%", cmap="YlOrRd_r", cbar_kws={"label": "VaR (%)"})
        plt.title("VaR percentage heat map (parametric)")
        plt.xlabel("level of trust")
        plt.ylabel("days of holding")
        plt.tight_layout()
        plt.savefig("2.png")



        pass



#st = PortfolioStressTester(config_path="config.json", portfolio_path="å§šæ³¾æ²³æŒä»“.xlsx")
#st.gen_report()






